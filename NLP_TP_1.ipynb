{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ue5hxxkdAQJg"
      },
      "source": [
        "<img src=\"https://github.com/FIUBA-Posgrado-Inteligencia-Artificial/procesamiento_lenguaje_natural/raw/main/logoFIUBA.jpg\" width=\"500\" align=\"center\">\n",
        "\n",
        "\n",
        "# Procesamiento de lenguaje natural\n",
        "## Vectorización\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kCED1hh-Ioyf"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PUbfVnzIIoMj"
      },
      "outputs": [],
      "source": [
        "def cosine_similarity(a, b):\n",
        "    return np.dot(a, b) / (np.linalg.norm(a) * (np.linalg.norm(b)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DMOa4JPSCJ29"
      },
      "source": [
        "### Datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RIO7b8GjAC17"
      },
      "outputs": [],
      "source": [
        "corpus = np.array(['que dia es hoy', 'martes el dia de hoy es martes', 'martes muchas gracias'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8WqdaTmO8P1r"
      },
      "source": [
        "Documento 1 --> que dia es hoy \\\n",
        "Documento 2 --> martes el dia de hoy es martes \\\n",
        "Documento 3 --> martes muchas gracias"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FVHxBRNzCMOS"
      },
      "source": [
        "### 1 - Obtener el vocabulario del corpus (los términos utilizados)\n",
        "- Cada documento transformarlo en una lista de términos\n",
        "- Armar un vector de términos no repetidos de todos los documentos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3ZqTOZzDI7uv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6266255b-c19b-4e2b-e013-5114b1690e12"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['de' 'dia' 'el' 'es' 'gracias' 'hoy' 'martes' 'muchas' 'que']\n"
          ]
        }
      ],
      "source": [
        "terminos = np.char.split(corpus)\n",
        "terminos_flat = np.concatenate(terminos)\n",
        "terminos_unicos = np.unique(terminos_flat)\n",
        "\n",
        "print(terminos_unicos)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RUhH983FI7It"
      },
      "source": [
        "### 2- OneHot encoding\n",
        "Data una lista de textos, devolver una matriz con la representación oneHotEncoding de estos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Os0AAQo6I6Z1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "58e8068d-f463-49bd-9a8a-129523684c9b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['de', 'dia', 'el', 'es', 'gracias', 'hoy', 'martes', 'muchas', 'que']\n",
            "[0, 1, 0, 1, 0, 1, 0, 0, 1]\n",
            "[1, 1, 1, 1, 0, 1, 1, 0, 0]\n",
            "[0, 0, 0, 0, 1, 0, 1, 1, 0]\n"
          ]
        }
      ],
      "source": [
        "ohe = np.zeros((len(corpus), len(terminos_unicos)), dtype=int)\n",
        "\n",
        "# Para cada documento, llenamos la matriz con 1s y 0s\n",
        "for i, doc in enumerate(terminos):\n",
        "    for termino in doc:\n",
        "        # Obtenemos el índice de la palabra en terminos unicos\n",
        "        idx = np.where(terminos_unicos == termino)\n",
        "\n",
        "        # Si el término se encuentra en terminos_unicos\n",
        "        if idx[0].size > 0:\n",
        "            # Ponemos un 1 en la posición correspondiente de la matriz\n",
        "            ohe[i, idx[0][0]] = 1\n",
        "\n",
        "\n",
        "# Creamos la matriz final como una lista, que puede contener diferentes tipos de datos\n",
        "final_ohe = [terminos_unicos.tolist()] + ohe.tolist()\n",
        "\n",
        "for row in final_ohe:\n",
        "    print(row)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IIyWGmCpJVQL"
      },
      "source": [
        "### 3- Vectores de frecuencia\n",
        "Data una lista de textos, devolver una matriz con la representación de frecuencia de estos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yqij_7eHJbUi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7354bb2b-f3e7-4eb2-9dd4-7527582b9112"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['de', 'dia', 'el', 'es', 'gracias', 'hoy', 'martes', 'muchas', 'que']\n",
            "[0, 1, 0, 1, 0, 1, 0, 0, 1]\n",
            "[1, 1, 1, 1, 0, 1, 2, 0, 0]\n",
            "[0, 0, 0, 0, 1, 0, 1, 1, 0]\n"
          ]
        }
      ],
      "source": [
        "# Creamos una matriz vacía de la forma correcta (número de documentos, número de palabras únicas)\n",
        "matrix = np.zeros((len(corpus), len(terminos_unicos)), dtype=int)\n",
        "\n",
        "# Para cada documento, llenamos la matriz con la cantidad de veces que aparece cada palabra\n",
        "for i, doc in enumerate(terminos):\n",
        "    for termino in doc:\n",
        "        # Obtenemos el índice de la palabra en terminos_unicos\n",
        "        idx = np.where(terminos_unicos == termino)[0][0]\n",
        "        # Aumentamos el contador en la posición correspondiente de la matriz\n",
        "        matrix[i, idx] += 1\n",
        "\n",
        "# Creamos la matriz final como una lista, que puede contener diferentes tipos de datos\n",
        "final_matrix = [terminos_unicos.tolist()] + matrix.tolist()\n",
        "\n",
        "for row in final_matrix:\n",
        "    print(row)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z_Ot8HvWJcBu"
      },
      "source": [
        "### 4- TF-IDF\n",
        "Data una lista de textos, devolver una matriz con la representacion TFIDF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "waG_oWtpJjRw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7720c3da-3a7e-46ac-8ac9-94a9271fb6cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matriz IDF:\n",
            "[['de' 'dia' 'el' 'es' 'gracias' 'hoy' 'martes' 'muchas' 'que']\n",
            " ['0.47712125471966244' '0.17609125905568124' '0.47712125471966244'\n",
            "  '0.17609125905568124' '0.47712125471966244' '0.17609125905568124'\n",
            "  '0.17609125905568124' '0.47712125471966244' '0.47712125471966244']]\n",
            "Matriz TF-IDF:\n",
            "['de', 'dia', 'el', 'es', 'gracias', 'hoy', 'martes', 'muchas', 'que']\n",
            "[0.0, 0.17609125905568124, 0.0, 0.17609125905568124, 0.0, 0.17609125905568124, 0.0, 0.0, 0.47712125471966244]\n",
            "[0.47712125471966244, 0.17609125905568124, 0.47712125471966244, 0.17609125905568124, 0.0, 0.17609125905568124, 0.3521825181113625, 0.0, 0.0]\n",
            "[0.0, 0.0, 0.0, 0.0, 0.47712125471966244, 0.0, 0.17609125905568124, 0.47712125471966244, 0.0]\n"
          ]
        }
      ],
      "source": [
        "from collections import Counter\n",
        "import math\n",
        "\n",
        "# Creamos una matriz vacía de la forma correcta (número de documentos, número de palabras únicas)\n",
        "tf_matrix = np.zeros((len(corpus), len(terminos_unicos)), dtype=int)\n",
        "\n",
        "# Calculamos TF para cada palabra en cada documento\n",
        "for i, doc in enumerate(terminos):\n",
        "    for termino in doc:\n",
        "        # Obtenemos el índice de la palabra en terminos_unicos\n",
        "        idx = np.where(terminos_unicos == termino)[0][0]\n",
        "        # Aumentamos el contador en la posición correspondiente de la matriz\n",
        "        tf_matrix[i, idx] += 1\n",
        "\n",
        "# Calculamos DF para cada palabra\n",
        "df = Counter(termino for doc in terminos for termino in np.unique(doc))\n",
        "\n",
        "# Calculamos IDF para cada palabra única\n",
        "idf_values = np.array([math.log(len(corpus) / df[termino],10) for termino in terminos_unicos])\n",
        "\n",
        "# Creamos la matriz TF-IDF multiplicando cada término de TF por su IDF correspondiente\n",
        "tfidf_matrix = np.zeros((len(corpus), len(terminos_unicos)), dtype=float)\n",
        "for i in range(len(corpus)):\n",
        "    for j in range(len(terminos_unicos)):\n",
        "        tfidf_matrix[i, j] = tf_matrix[i, j] * idf_values[j]\n",
        "\n",
        "# Creamos las matrices finales como listas, que pueden contener diferentes tipos de datos\n",
        "final_matrix_idf = np.array([terminos_unicos, idf_values])\n",
        "final_matrix_tfidf = [terminos_unicos.tolist()] + tfidf_matrix.tolist()\n",
        "\n",
        "print(\"Matriz IDF:\")\n",
        "print(final_matrix_idf)\n",
        "print(\"Matriz TF-IDF:\")\n",
        "for row in final_matrix_tfidf:\n",
        "    print(row)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xMcsfndWJjm_"
      },
      "source": [
        "### 5 - Comparación de documentos\n",
        "Realizar una funcion que reciba el corpus y el índice de un documento y devuelva los documentos ordenados por la similitud coseno"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CZdiop6IJpZN"
      },
      "outputs": [],
      "source": [
        "def tf_idf(corpus):\n",
        "    words = np.char.split(corpus)\n",
        "    flat_words = np.concatenate(words)\n",
        "    unique_words = np.unique(flat_words)\n",
        "\n",
        "    tf_matrix = np.zeros((len(corpus), len(unique_words)), dtype=int)\n",
        "    for i, doc in enumerate(words):\n",
        "        for word in doc:\n",
        "            idx = np.where(unique_words == word)[0][0]\n",
        "            tf_matrix[i, idx] += 1\n",
        "\n",
        "    df = Counter(word for doc in words for word in np.unique(doc))\n",
        "    idf_values = np.array([math.log(len(corpus) / df[word]) for word in unique_words])\n",
        "\n",
        "    tfidf_matrix = np.zeros((len(corpus), len(unique_words)), dtype=float)\n",
        "    for i in range(len(corpus)):\n",
        "        for j in range(len(unique_words)):\n",
        "            tfidf_matrix[i, j] = tf_matrix[i, j] * idf_values[j]\n",
        "    \n",
        "    return tfidf_matrix\n",
        "\n",
        "def get_similar_documents(corpus, doc_index):\n",
        "    tfidf_matrix = tf_idf(corpus)\n",
        "    similarities = [cosine_similarity(tfidf_matrix[doc_index], tfidf_matrix[i]) for i in range(len(corpus))]\n",
        "    sorted_indices = np.argsort(similarities)[::-1]\n",
        "    \n",
        "    return corpus[sorted_indices]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf_idf(corpus)"
      ],
      "metadata": {
        "id": "attzyZt-oODK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76cbc832-232a-4307-b6b5-ed1510b64ce8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.        , 0.40546511, 0.        , 0.40546511, 0.        ,\n",
              "        0.40546511, 0.        , 0.        , 1.09861229],\n",
              "       [1.09861229, 0.40546511, 1.09861229, 0.40546511, 0.        ,\n",
              "        0.40546511, 0.81093022, 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 1.09861229,\n",
              "        0.        , 0.40546511, 1.09861229, 0.        ]])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(get_similar_documents(corpus, 0))\n",
        "print(get_similar_documents(corpus, 1))\n",
        "print(get_similar_documents(corpus, 2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iz0lCW_OzBvE",
        "outputId": "f3dad9dd-7079-44cd-9967-d0356e507e4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['que dia es hoy' 'martes el dia de hoy es martes' 'martes muchas gracias']\n",
            "['martes el dia de hoy es martes' 'que dia es hoy' 'martes muchas gracias']\n",
            "['martes muchas gracias' 'martes el dia de hoy es martes' 'que dia es hoy']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "corpus = np.array([\n",
        "    'sal de ahí chivita chivita',\n",
        "    'sal de ahí de ese lugar', \n",
        "    'vamos a buscar al palo',\n",
        "    'para que le pegue al lobo',\n",
        "    'el palo no quiere pegarle al lobo',\n",
        "    'el lobo no quiere sacar a la chiva',\n",
        "    'la chiva no quiere salir de ahí'\n",
        "    ])\n",
        "\n",
        "for i, doc in enumerate(corpus):\n",
        "    print(get_similar_documents(corpus, i))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GLU6-00E1sQe",
        "outputId": "b9aaf4a7-99d1-4f9e-8fee-79bf99ceca75"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['sal de ahí chivita chivita' 'sal de ahí de ese lugar'\n",
            " 'la chiva no quiere salir de ahí' 'el lobo no quiere sacar a la chiva'\n",
            " 'el palo no quiere pegarle al lobo' 'para que le pegue al lobo'\n",
            " 'vamos a buscar al palo']\n",
            "['sal de ahí de ese lugar' 'sal de ahí chivita chivita'\n",
            " 'la chiva no quiere salir de ahí' 'el lobo no quiere sacar a la chiva'\n",
            " 'el palo no quiere pegarle al lobo' 'para que le pegue al lobo'\n",
            " 'vamos a buscar al palo']\n",
            "['vamos a buscar al palo' 'el palo no quiere pegarle al lobo'\n",
            " 'el lobo no quiere sacar a la chiva' 'para que le pegue al lobo'\n",
            " 'la chiva no quiere salir de ahí' 'sal de ahí de ese lugar'\n",
            " 'sal de ahí chivita chivita']\n",
            "['para que le pegue al lobo' 'el palo no quiere pegarle al lobo'\n",
            " 'vamos a buscar al palo' 'el lobo no quiere sacar a la chiva'\n",
            " 'la chiva no quiere salir de ahí' 'sal de ahí de ese lugar'\n",
            " 'sal de ahí chivita chivita']\n",
            "['el palo no quiere pegarle al lobo' 'el lobo no quiere sacar a la chiva'\n",
            " 'vamos a buscar al palo' 'la chiva no quiere salir de ahí'\n",
            " 'para que le pegue al lobo' 'sal de ahí de ese lugar'\n",
            " 'sal de ahí chivita chivita']\n",
            "['el lobo no quiere sacar a la chiva' 'la chiva no quiere salir de ahí'\n",
            " 'el palo no quiere pegarle al lobo' 'vamos a buscar al palo'\n",
            " 'para que le pegue al lobo' 'sal de ahí de ese lugar'\n",
            " 'sal de ahí chivita chivita']\n",
            "['la chiva no quiere salir de ahí' 'el lobo no quiere sacar a la chiva'\n",
            " 'sal de ahí de ese lugar' 'el palo no quiere pegarle al lobo'\n",
            " 'sal de ahí chivita chivita' 'para que le pegue al lobo'\n",
            " 'vamos a buscar al palo']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YMJLkrXm10a9"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}